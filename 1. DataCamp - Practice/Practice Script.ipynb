{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b120d877",
   "metadata": {},
   "source": [
    "## 1. Introduction to Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c344a1",
   "metadata": {},
   "source": [
    "### a. Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f3f7c5",
   "metadata": {},
   "source": [
    "#### i. Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ed9679",
   "metadata": {},
   "source": [
    "#### ii. Type of the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c3efe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb93ff",
   "metadata": {},
   "source": [
    "### b. Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d45b42",
   "metadata": {},
   "source": [
    "#### i. Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc40092e",
   "metadata": {},
   "source": [
    "#### ii. Sub-lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4f6d19",
   "metadata": {},
   "source": [
    "#### iii. Sub-setting lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2067c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "house = [[\"hallway\", 11.25],\n",
    "         [\"kitchen\", 18.0],\n",
    "         [\"living room\", 20.0],\n",
    "         [\"bedroom\", 10.75],\n",
    "         [\"bathroom\", 9.50]]\n",
    "\n",
    "# Subset the house list\n",
    "house[4][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661c919d",
   "metadata": {},
   "source": [
    "#### iv. Slicing \n",
    " \n",
    " - my_list[start:end]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a30270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the areas list\n",
    "areas = [\"hallway\", 11.25, \"kitchen\", 18.0, \"living room\", 20.0, \"bedroom\", 10.75, \"bathroom\", 9.50]\n",
    "\n",
    "# Use slicing to create downstairs\n",
    "downstairs = areas[:6]\n",
    "\n",
    "# Use slicing to create upstairs\n",
    "upstairs = areas[-4:]\n",
    "\n",
    "# Print out downstairs and upstairs\n",
    "print(downstairs)\n",
    "print(upstairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf0b21",
   "metadata": {},
   "source": [
    "#### v. Replacing elements or adding elements or deleting elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90780a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas[9] = 10.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_1 = areas + [\"poolhouse\", 24.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe23aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del areas[10:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65719983",
   "metadata": {},
   "source": [
    "### c. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a90b93",
   "metadata": {},
   "source": [
    "#### i. Sorting a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f585c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists first and second\n",
    "first = [11.25, 18.0, 20.0]\n",
    "second = [10.75, 9.50]\n",
    "\n",
    "# Paste together first and second: full\n",
    "full = first + second\n",
    "\n",
    "# Sort full in descending order: full_sorted\n",
    "full_sorted = sorted(full, reverse = True)\n",
    "\n",
    "# Print out full_sorted\n",
    "print(full_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bfdbc5",
   "metadata": {},
   "source": [
    "#### ii. String Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb80080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string to experiment with: place\n",
    "place = \"poolhouse\"\n",
    "\n",
    "# Use upper() on place\n",
    "place_up = place.upper()\n",
    "\n",
    "# Print out the number of o's in place\n",
    "print(place.count(\"o\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807d339",
   "metadata": {},
   "source": [
    "### d. Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77ef902",
   "metadata": {},
   "source": [
    "#### i. Creating 2D numpy array \n",
    " - Helps perform calculations element by element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Create a numpy array from height_in: np_height_in\n",
    "np_height_in = np.array(height_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e73ad08",
   "metadata": {},
   "source": [
    "#### ii. Basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ba9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np_baseball)\n",
    "# Create np_height_in from np_baseball\n",
    "np_height_in = np.array(np_baseball[:,0])\n",
    "\n",
    "# Print out the mean of np_height_in\n",
    "print(np.mean(np_height_in))\n",
    "\n",
    "# Print out the median of np_height_in\n",
    "print(np.median(np_height_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad672438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609961e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3698a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d64ab87",
   "metadata": {},
   "source": [
    "## 2. Intermediate Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e849df0b",
   "metadata": {},
   "source": [
    "### a. Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b03ed3",
   "metadata": {},
   "source": [
    "#### i. line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1a2624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the last item from year and pop\n",
    "print(year[-1])\n",
    "print(pop[-1])\n",
    "\n",
    "\n",
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make a line plot: year on the x-axis, pop on the y-axis\n",
    "plt.plot(year,pop)\n",
    "\n",
    "# Display the plot with plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed32e9a",
   "metadata": {},
   "source": [
    "<img src=\"/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Important_Scripts-Practice/1. DataCamp - Practice/Images/linePLot.svg\" width=\"500\" height=\"300\" alt=\"Description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7abe9c",
   "metadata": {},
   "source": [
    "#### ii. Scatter PLot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75ebb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Scatter plot\n",
    "plt.scatter(pop, life_exp)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529ec375",
   "metadata": {},
   "source": [
    "<img src=\"/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Important_Scripts-Practice/1. DataCamp - Practice/Images/Scatter.svg\" width=\"500\" height=\"300\" alt=\"Description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb2f754",
   "metadata": {},
   "source": [
    "#### iii. Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376662c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram of life_exp data\n",
    "plt.hist(life_exp)\n",
    "\n",
    "# Display histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f74f97c",
   "metadata": {},
   "source": [
    "<img src=\"/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Important_Scripts-Practice/1. DataCamp - Practice/Images/Hist.svg\" width=\"500\" height=\"300\" alt=\"Description\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of life_exp, 15 bins\n",
    "plt.hist(life_exp, bins = 15)\n",
    "\n",
    "# Show and clear plot\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# Histogram of life_exp1950, 15 bins\n",
    "plt.hist(life_exp1950, bins = 15)\n",
    "\n",
    "# Show and clear plot again\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c62eec",
   "metadata": {},
   "source": [
    "<img src=\"/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Important_Scripts-Practice/1. DataCamp - Practice/Images/HistBins.svg\" width=\"500\" height=\"300\" alt=\"Description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9145c181",
   "metadata": {},
   "source": [
    "#### iv. Labelling convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9830d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "plt.scatter(x = gdp_cap, y = life_exp, s = np.array(pop) * 2, c = col, alpha = 0.8)\n",
    "\n",
    "# Previous customizations\n",
    "plt.xscale('log') \n",
    "plt.xlabel('GDP per Capita [in USD]')\n",
    "plt.ylabel('Life Expectancy [in years]')\n",
    "plt.title('World Development in 2007')\n",
    "plt.xticks([1000,10000,100000], ['1k','10k','100k'])\n",
    "\n",
    "# Additional customizations\n",
    "plt.text(1550, 71, 'India')\n",
    "plt.text(5700, 80, 'China')\n",
    "\n",
    "# Add grid() call\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f0908b",
   "metadata": {},
   "source": [
    "### b. Dictionaries & Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6875a289",
   "metadata": {},
   "source": [
    "``` \n",
    "my_dict = {\n",
    "   \"key1\":\"value1\",\n",
    "   \"key2\":\"value2\",\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c5868d",
   "metadata": {},
   "source": [
    "#### i. Accessing Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad32b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of dictionary\n",
    "europe = {'spain':'madrid', 'france':'paris', 'germany':'berlin', 'norway':'oslo' }\n",
    "\n",
    "# Print out the keys in europe\n",
    "print(europe.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43a396b",
   "metadata": {},
   "source": [
    "#### ii. Deleting key and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde2bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(europe[\"spain\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c31f151",
   "metadata": {},
   "source": [
    "#### iii. Dict to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9695cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-defined lists\n",
    "names = ['United States', 'Australia', 'Japan', 'India', 'Russia', 'Morocco', 'Egypt']\n",
    "dr =  [True, False, False, False, True, True, True]\n",
    "cpc = [809, 731, 588, 18, 200, 70, 45]\n",
    "\n",
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "# Create dictionary my_dict with three key:value pairs: my_dict\n",
    "my_dict = {'country':names,'drives_right':dr,'cars_per_cap':cpc}\n",
    "\n",
    "# Build a DataFrame cars from my_dict: cars\n",
    "cars = pd.DataFrame(my_dict)\n",
    "\n",
    "# Print cars\n",
    "print(cars)\n",
    "\n",
    "# Definition of row_labels\n",
    "row_labels = ['US', 'AUS', 'JPN', 'IN', 'RU', 'MOR']\n",
    "\n",
    "# Specify row labels of cars\n",
    "cars.index = row_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f83f532",
   "metadata": {},
   "source": [
    "#### iv. Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15551cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix import by including index_col\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab4ed82",
   "metadata": {},
   "source": [
    "#### v. Accessing portion of data as Series or Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44723ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out country column as Pandas Series\n",
    "print(cars[\"country\"])\n",
    "\n",
    "# Print out country column as Pandas DataFrame\n",
    "print(cars[[\"country\"]])\n",
    "\n",
    "# Print out DataFrame with country and drives_right columns\n",
    "print(cars[[\"country\",\"drives_right\"]])\n",
    "\n",
    "#Or \n",
    "# Print out first 3 observations\n",
    "print(cars[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8b755b",
   "metadata": {},
   "source": [
    "#### vi. Accessing portion of data with .loc or .iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e2c21f",
   "metadata": {},
   "source": [
    "```\n",
    "Starts with Rows and column \n",
    "\n",
    "cars.loc[['IN', 'RU'], 'cars_per_cap']\n",
    "cars.iloc[[3, 4], 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eadc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out observations for Australia and Egypt \n",
    "print(cars.loc[[\"AUS\",\"EG\"]]) # AUS and EG are index\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136963a3",
   "metadata": {},
   "source": [
    "#### vii. Access all rows but only with selected column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95af0f21",
   "metadata": {},
   "source": [
    "```\n",
    ": -> to select all the rows\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3deac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.loc[:, ['country','drives_right']]\n",
    "cars.iloc[:, [1, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd94b1",
   "metadata": {},
   "source": [
    "### c. Logic, Control flow and Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18ad986",
   "metadata": {},
   "source": [
    "#### i. Comparison operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d5a846",
   "metadata": {},
   "source": [
    "```\n",
    "== \n",
    "!=\n",
    "<\n",
    ">\n",
    "=<\n",
    ">=\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a32732",
   "metadata": {},
   "source": [
    "#### ii. Boolean Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e536431",
   "metadata": {},
   "source": [
    "```\n",
    "True -> 0\n",
    "False -> 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa8e41",
   "metadata": {},
   "source": [
    "#### iv. And, Or operator through numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f25537",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_house = np.array([18.0, 20.0, 10.75, 9.50])\n",
    "your_house = np.array([14.0, 24.0, 14.25, 9.0])\n",
    "\n",
    "# my_house greater than 18.5 or smaller than 10\n",
    "print(np.logical_or(my_house > 18.5, my_house < 10))\n",
    "\n",
    "# Both my_house and your_house smaller than 11\n",
    "print(np.logical_and(my_house < 11, your_house < 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Create medium: observations with cars_per_cap between 100 and 500\n",
    "cpc = cars['cars_per_cap']\n",
    "between = np.logical_and(cpc > 100, cpc < 500)\n",
    "medium = cars[between]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d872de6",
   "metadata": {},
   "source": [
    "#### v. if, elif, else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab00aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = 10.0\n",
    "if(area < 9) :\n",
    "    print(\"small\")\n",
    "elif(area < 12) :\n",
    "    print(\"medium\")\n",
    "else :\n",
    "    print(\"large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818e1e86",
   "metadata": {},
   "source": [
    "#### vi. While Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7943d",
   "metadata": {},
   "source": [
    "The while loop is like a repeated if statement. The code is executed over and over again, as long as the condition is ```True```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16161540",
   "metadata": {},
   "source": [
    "``` \n",
    "while condition :\n",
    "    expression\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee58107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize offset\n",
    "offset = -6\n",
    "\n",
    "# Code the while loop\n",
    "while offset != 0 :\n",
    "    print(\"correcting...\")\n",
    "    if offset > 0 :\n",
    "      offset = offset - 1\n",
    "    else : \n",
    "      offset = offset + 1    \n",
    "    print(offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83300e4d",
   "metadata": {},
   "source": [
    "#### vii. Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bca456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# areas list\n",
    "areas = [11.25, 18.0, 20.0, 10.75, 9.50]\n",
    "\n",
    "# Code the for loop\n",
    "for i in areas:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc639776",
   "metadata": {},
   "source": [
    "a. Loop over multiple lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f2967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# house list of lists\n",
    "house = [[\"hallway\", 11.25], \n",
    "         [\"kitchen\", 18.0], \n",
    "         [\"living room\", 20.0], \n",
    "         [\"bedroom\", 10.75], \n",
    "         [\"bathroom\", 9.50]]\n",
    "         \n",
    "# Build a for loop from scratch\n",
    "for i in house:\n",
    "    room_name = i[0]\n",
    "    room_area = i[1]\n",
    "    print(\"the \" + room_name + \" is \" + str(room_area) + \" sqm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1529d731",
   "metadata": {},
   "source": [
    "b. loop over dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ecd2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of dictionary\n",
    "europe = {'spain':'madrid', 'france':'paris', 'germany':'berlin',\n",
    "          'norway':'oslo', 'italy':'rome', 'poland':'warsaw', 'austria':'vienna' }\n",
    "          \n",
    "# Iterate over europe\n",
    "\n",
    "for k, v in europe.items():\n",
    "    print(\"the capital of \" + str(k) + \" is \" + str(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b86dfbc",
   "metadata": {},
   "source": [
    "c. Loop over numpy array\n",
    " - 1D array and\n",
    " - 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df9ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy as np\n",
    "import numpy as np\n",
    "\n",
    "# For loop over np_height\n",
    "for i in np_height:\n",
    "    print(str(i) + \" inches\") # This is for 1D array\n",
    "\n",
    "# For loop over np_baseball\n",
    "for i in np.nditer(np_baseball):# This is for 2D array | we use np.nditer() to iterate over 2D array\n",
    "    print(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee658a",
   "metadata": {},
   "source": [
    "d. ***Loop over a DataFrame*** -> we use iterrows()\n",
    "\n",
    "\n",
    " - DataFrame.iterrows() yields pairs: (index_label, row_series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f001cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "print(cars)\n",
    "# Iterate over rows of cars\n",
    "\n",
    "for label, row in cars.iterrows():\n",
    "    print(label)\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd36b23e",
   "metadata": {},
   "source": [
    "Use a for loop to add a new column, named COUNTRY, that contains a uppercase version of the country names in the \"country\" column. You can use the string method upper() for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b61b1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Code for loop that adds COUNTRY column\n",
    "for lab, row in car.itterows():\n",
    "    cars.loc[lab, \"COUNTRY\"] = row[\"country\"].upper\n",
    "\n",
    "\n",
    "# Print cars\n",
    "print(cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3ab916",
   "metadata": {},
   "source": [
    "Vectorize operators for above with simple code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb5aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[\"COUNTRY\"] = cars[\"country\"].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd005e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b779e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "799688be",
   "metadata": {},
   "source": [
    "```\n",
    "What enumerate() does\n",
    "\n",
    "Signature: enumerate(iterable, start=0) -> It returns an iterator that yields pairs (index, value) for each item in the iterable.\n",
    "\n",
    "By default, indexing starts at 0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db91920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = [11.25, 18.0, 20.0, 10.75, 9.50]\n",
    "\n",
    "for index, a in enumerate(areas, start=1):\n",
    "    print(\"room \" + str(index) + \": \" + str(a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f66a71",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0b739c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38eef7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ebc827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "708aa1dd",
   "metadata": {},
   "source": [
    "## 3. Data Manipulation with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0845a00d",
   "metadata": {},
   "source": [
    "### a. Transforming Data Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714bc9c1",
   "metadata": {},
   "source": [
    "#### i. Understanding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19de7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the head of the homelessness data\n",
    "print(homelessness.head())\n",
    "\n",
    "# Print information about homelessness\n",
    "print(homelessness.info())\n",
    "\n",
    "# Print the shape of homelessness\n",
    "print(homelessness.shape)\n",
    "\n",
    "# Print a description of homelessness\n",
    "print(homelessness.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950b9f5",
   "metadata": {},
   "source": [
    "#### ii. Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ce7273",
   "metadata": {},
   "source": [
    "Single column vs Multiple columns\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "one column       ->\tdf.sort_values(\"breed\")\n",
    "multiple columns ->\tdf.sort_values([\"breed\", \"weight_kg\"])\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort homelessness by individuals\n",
    "homelessness_ind = homelessness.sort_values(\"individuals\")\n",
    "\n",
    "# Sort homelessness by descending family members\n",
    "homelessness_fam = homelessness.sort_values(\"family_members\", ascending = False)\n",
    "\n",
    "# Sort homelessness by region, then descending family members\n",
    "homelessness_reg_fam = homelessness.sort_values([\"region\",\"family_members\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9009e798",
   "metadata": {},
   "source": [
    "#### iii. Selecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72425cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As series\n",
    "individuals = homelessness[\"individuals\"]\n",
    "\n",
    "# As dataframe\n",
    "ind_subset = homelessness[[\"individuals\",\"region\",\"state\"]]\n",
    "\n",
    "# Subset with .loc\n",
    "ind_subset = homelessness.loc[:, [\"individuals\",\"region\",\"state\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b5163c",
   "metadata": {},
   "source": [
    "#### iv. Filtering rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for rows where individuals is greater than 10000\n",
    "ind_gt_10k = homelessness[homelessness[\"individuals\"] > 10000]\n",
    "# Filter for rows where region is Mountain\n",
    "mountain_reg = homelessness[homelessness[\"region\"] == \"Mountain\"]\n",
    "\n",
    "# Filter for rows where family_members is less than 1000 and region is Pacific\n",
    "fam_lt_1k_pac = homelessness[(homelessness[\"family_members\"] < 1000) &(homelessness[\"region\"] == \"Pacific\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138f005a",
   "metadata": {},
   "source": [
    "#### v. Subsetting Rows by categorised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a68bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Mojave Desert states\n",
    "canu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n",
    "\n",
    "# Filter for rows in the Mojave Desert states\n",
    "mojave_homelessness = homelessness[homelessness[\"state\"].isin(canu)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8007b4",
   "metadata": {},
   "source": [
    "#### vi. Adding New column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add total col as sum of individuals and family_members\n",
    "homelessness[\"total\"] =  homelessness[\"individuals\"] + homelessness[\"family_members\"]\n",
    "\n",
    "# Add p_homeless col as proportion of total homeless population to the state population\n",
    "homelessness[\"p_homeless\"] = homelessness[\"total\"]/homelessness[\"state_pop\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2956e11c",
   "metadata": {},
   "source": [
    "#### vii. Activity : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc69f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indiv_per_10k col as homeless individuals per 10k state pop\n",
    "homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"] \n",
    "\n",
    "# Subset rows for indiv_per_10k greater than 20\n",
    "high_homelessness = homelessness[homelessness[\"indiv_per_10k\"] > 20]\n",
    "\n",
    "# Sort high_homelessness by descending indiv_per_10k\n",
    "high_homelessness_srt = high_homelessness.sort_values(\"indiv_per_10k\", ascending=False)\n",
    "\n",
    "# From high_homelessness_srt, select the state and indiv_per_10k cols\n",
    "result = high_homelessness_srt[[\"state\", \"indiv_per_10k\" ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bedec62",
   "metadata": {},
   "source": [
    "### b. Aggregating DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a951b70a",
   "metadata": {},
   "source": [
    "#### i. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b86d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean of weekly_sales\n",
    "print(sales[\"weekly_sales\"].mean())\n",
    "\n",
    "# Print the median of weekly_sales\n",
    "print(sales[\"weekly_sales\"].median())\n",
    "\n",
    "# Print the maximum of the date column\n",
    "print(sales[\"date\"].max())\n",
    "\n",
    "# Print the minimum of the date column\n",
    "print(sales[\"date\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d09af18",
   "metadata": {},
   "source": [
    "#### ii. Computing IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b00308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "# Print IQR of the temperature_c column\n",
    "print(sales[\"temperature_c\"].agg(iqr))\n",
    "\n",
    "# Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg(iqr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52143185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr,np.median]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff71c418",
   "metadata": {},
   "source": [
    "#### iii. Cummulative Sum\n",
    "\n",
    "Remember - Date should be sorted Ascending for the cummulative to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc70e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort sales_1_1 by date\n",
    "sales_1_1 = sales_1_1.sort_values(\"date\")\n",
    "\n",
    "# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\n",
    "sales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ac446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cumulative max of weekly_sales, add as cum_max_sales col\n",
    "sales_1_1[\"cum_max_sales\"] = sales_1_1[\"weekly_sales\"].cummax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b0c891",
   "metadata": {},
   "source": [
    "#### iv. Dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3240d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate store/type combinations\n",
    "store_types = sales.drop_duplicates([\"store\", \"type\"])\n",
    "print(store_types.head())\n",
    "\n",
    "# Drop duplicate store/department combinations\n",
    "store_depts = sales.drop_duplicates([\"store\", \"department\"])\n",
    "print(store_depts.head())\n",
    "\n",
    "# Subset the rows where is_holiday is True and drop duplicate dates\n",
    "holiday_dates = sales[sales[\"is_holiday\"]].drop_duplicates(\"date\")\n",
    "\n",
    "# Print date col of holiday_dates\n",
    "print(holiday_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2e51c9",
   "metadata": {},
   "source": [
    "#### v. Counting Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a7f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of stores of each type\n",
    "store_counts = store_types[\"type\"].value_counts()\n",
    "print(store_counts)\n",
    "\n",
    "# Get the proportion of stores in each department and sort\n",
    "dept_props_sorted = store_depts[\"department\"].value_counts(sort=True, normalize=True)\n",
    "print(dept_props_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0950acf3",
   "metadata": {},
   "source": [
    "#### vi. Grouped Summary statistics - Group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e6c07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by type; calc total weekly sales\n",
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "# For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\n",
    "unemp_fuel_stats = sales.groupby(\"type\")[[\"unemployment\",\"fuel_price_usd_per_l\"]].agg([min, max, np.mean, np.median])\n",
    "\n",
    "\n",
    "# Get proportion for each type\n",
    "sales_propn_by_type = sales_by_type / sum(sales[\"weekly_sales\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8623fc58",
   "metadata": {},
   "source": [
    "#### vii. Pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63453c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot for mean weekly_sales for each store type\n",
    "mean_sales_by_type = sales.pivot_table(values=\"weekly_sales\",index=\"type\")\n",
    "\n",
    "# Pivot for mean and median weekly_sales for each store type\n",
    "mean_med_sales_by_type = sales.pivot_table(index = \"type\",values = \"weekly_sales\", aggfunc = [np.mean, np.median])\n",
    "\n",
    "# Pivot for mean weekly_sales by store type and holiday \n",
    "mean_sales_by_type_holiday = sales.pivot_table(index = \"type\", values = \"weekly_sales\", columns = \"is_holiday\")\n",
    "\n",
    "#handling missing values\n",
    "print(sales.pivot_table(index = \"type\", columns = \"department\", values=\"weekly_sales\", fill_value = 0))\n",
    "\n",
    "\n",
    "# Summarizing all rows and columns\n",
    "print(sales.pivot_table(values=\"weekly_sales\", index=\"department\", columns=\"type\", fill_value = 0, margins = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1d1d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot avg_temp_c by country and city vs year\n",
    "temp_by_country_city_vs_year = temperatures.pivot_table(values = \"avg_temp_c\", index = ['country', 'city'], columns = \"year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf88dd49",
   "metadata": {},
   "source": [
    "<img src=\"/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Important_Scripts-Practice/1. DataCamp - Practice/Images/Pivot table.png\" width=\"500\" height=\"300\" alt=\"Description\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfe5316",
   "metadata": {},
   "source": [
    "### c. Slicing and Indexing DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8093ada7",
   "metadata": {},
   "source": [
    "#### i. Setting and removing indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b6e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index of temperatures to city\n",
    "temperatures_ind = temperatures.set_index(\"city\")\n",
    "\n",
    "# Reset the temperatures_ind index, keeping its contents\n",
    "print(temperatures_ind.reset_index())\n",
    "\n",
    "# Reset the temperatures_ind index, dropping its contents\n",
    "print(temperatures_ind.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ba1cb",
   "metadata": {},
   "source": [
    "#### ii. using .isin() and .loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc8a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of cities to subset on\n",
    "cities = [\"Moscow\", \"Saint Petersburg\"]\n",
    "\n",
    "# Subset temperatures using square brackets\n",
    "print(temperatures[temperatures[\"city\"].isin(cities)])\n",
    "\n",
    "# Subset temperatures_ind using .loc[]\n",
    "print(temperatures_ind.loc[cities])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ba87e2",
   "metadata": {},
   "source": [
    "#### iii. Multi-Level indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a7e745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index temperatures by country & city\n",
    "temperatures_ind = temperatures.set_index([\"country\",\"city\"])\n",
    "\n",
    "# List of tuples: Brazil, Rio De Janeiro & Pakistan, Lahore\n",
    "rows_to_keep = [(\"Brazil\", \"Rio De Janeiro\"), ('India', \"Delhi\")] \n",
    "\n",
    "# Subset for rows to keep\n",
    "print(temperatures_ind.loc[rows_to_keep])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94a3fb3",
   "metadata": {},
   "source": [
    "#### iv. Sorting by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temperatures_ind.sort_index(level = [\"country\",\"city\"], ascending = [True,False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3115322",
   "metadata": {},
   "source": [
    "#### v. Slicing rows, or columns or both ways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb230f5",
   "metadata": {},
   "source": [
    "```\n",
    "Slice rows with code      --> df.loc[(\"a\", \"b\"):(\"c\", \"d\")].\n",
    "\n",
    "Slice columns with code   --> df.loc[:, \"e\":\"f\"].\n",
    "\n",
    "Slice both ways with code --> df.loc[(\"a\", \"b\"):(\"c\", \"d\"), \"e\":\"f\"]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e207302",
   "metadata": {},
   "source": [
    "#### v. Slicing Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0021f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Boolean conditions to subset temperatures for rows in 2010 and 2011\n",
    "temperatures_bool = temperatures[(temperatures[\"date\"] >= \"2010-01-01\") & (temperatures[\"date\"] <= \"2011-12-31\")]\n",
    "print(temperatures_bool)\n",
    "\n",
    "# Set date as the index and sort the index\n",
    "temperatures_ind = temperatures.set_index(\"date\").sort_index()\n",
    "\n",
    "# Use .loc[] to subset temperatures_ind for rows in 2010 and 2011\n",
    "print(temperatures_ind.loc[\"2010-01-01\":\"2011-12-31\"])\n",
    "\n",
    "# Use .loc[] to subset temperatures_ind for rows from Aug 2010 to Feb 2011\n",
    "print(temperatures_ind.loc[\"2010-08-01\":\"2011-02-28\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7039fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 23rd row, 2nd column (index 22, 1)\n",
    "print(temperatures.iloc[22,2])\n",
    "\n",
    "# Use slicing to get the first 5 rows\n",
    "print(temperatures.iloc[:5])\n",
    "\n",
    "# Use slicing to get columns 3 to 4\n",
    "print(temperatures.iloc[:,2:4])\n",
    "\n",
    "# Use slicing in both directions at once\n",
    "print(temperatures.iloc[:5,2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b67896a",
   "metadata": {},
   "source": [
    "### d. Creating and Visualizing DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a11643",
   "metadata": {},
   "source": [
    "#### i. Visualizing groupby and plotting categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a090a7f4",
   "metadata": {},
   "source": [
    "Data looks as under"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267e37d5",
   "metadata": {},
   "source": [
    "<img src=\"/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Important_Scripts-Practice/1. DataCamp - Practice/Images/Data1\n",
    ".png\" width=\"500\" height=\"300\" alt=\"Description\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total number of avocados sold of each size\n",
    "nb_sold_by_size = avocados.groupby(\"size\")[\"nb_sold\"].sum()\n",
    "\n",
    "# Create a bar plot of the number of avocados sold by size\n",
    "nb_sold_by_size.plot(kind=\"bar\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b27e634",
   "metadata": {},
   "source": [
    "<img src=\"/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Important_Scripts-Practice/1. DataCamp - Practice/Images/bar.svg\" width=\"500\" height=\"300\" alt=\"Description\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4fa180",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_sold_by_date = avocados.groupby(\"date\")[\"nb_sold\"].sum()\n",
    "\n",
    "# Create a line plot of the number of avocados sold by date\n",
    "nb_sold_by_date.plot(kind=\"line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65fc065",
   "metadata": {},
   "source": [
    "<img src=\"/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Important_Scripts-Practice/1. DataCamp - Practice/Images/line.svg\" width=\"500\" height=\"300\" alt=\"Description\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718423d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "avocados.plot(x=\"nb_sold\", y=\"avg_price\", kind=\"scatter\", title=\"Number of avocados sold vs. average price\")\n",
    "plt.title(\"Number of avocados sold vs. average price\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf32a7",
   "metadata": {},
   "source": [
    "<img src=\"/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Important_Scripts-Practice/1. DataCamp - Practice/Images/scat.svg\" width=\"500\" height=\"300\" alt=\"Description\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify histogram transparency to 0.5 \n",
    "avocados[avocados[\"type\"] == \"conventional\"][\"avg_price\"].hist(alpha=0.5)\n",
    "\n",
    "# Modify histogram transparency to 0.5\n",
    "avocados[avocados[\"type\"] == \"organic\"][\"avg_price\"].hist(alpha=0.5)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend([\"conventional\", \"organic\"])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e861a5",
   "metadata": {},
   "source": [
    "<img src=\"/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Important_Scripts-Practice/1. DataCamp - Practice/Images/hist-no overlap.svg\" width=\"500\" height=\"300\" alt=\"Without Overlap\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27627156",
   "metadata": {},
   "source": [
    "Using alpha - \n",
    "\n",
    "\n",
    "<img src=\"/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Important_Scripts-Practice/1. DataCamp - Practice/Images/WithOverlap.svg\" width=\"500\" height=\"300\" alt=\"Without Overlap\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26722213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b273fecd",
   "metadata": {},
   "source": [
    "Hist with Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8aee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify bins to 20\n",
    "avocados[avocados[\"type\"] == \"conventional\"][\"avg_price\"].hist(alpha=0.5, bins = 20)\n",
    "\n",
    "# Modify bins to 20\n",
    "avocados[avocados[\"type\"] == \"organic\"][\"avg_price\"].hist(alpha=0.5, bins = 20)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend([\"conventional\", \"organic\"])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07103421",
   "metadata": {},
   "source": [
    "#### ii. handling - Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea64695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot with alias plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check individual values for missing values\n",
    "print(avocados_2016.isna())\n",
    "\n",
    "# Check each column for missing values\n",
    "print(avocados_2016.isna().any())\n",
    "\n",
    "# Bar plot of missing values by variable\n",
    "avocados_2016.isna().sum().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "avocados_complete = avocados_2016.dropna()\n",
    "\n",
    "# Check if any columns contain missing values\n",
    "print(avocados_complete.isna().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b31dc77",
   "metadata": {},
   "source": [
    "## 4. Joining Data with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0ea610",
   "metadata": {},
   "source": [
    "### a. Data Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b3de6c",
   "metadata": {},
   "source": [
    "#### i. Inner Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec442ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df.merge(df_right, on = \"common_column\")\n",
    "\n",
    "\n",
    "# we can have multiple common columns\n",
    "df_merged = df.merge(df_right, on = [\"common_column_1\", \"common_column_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03df094",
   "metadata": {},
   "source": [
    "#### ii. Multiple Table merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb665ecf",
   "metadata": {},
   "source": [
    "<img src=\"/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Important_Scripts-Practice/1. DataCamp - Practice/Images/Relationship.png\" width=\"500\" height=\"300\" alt=\"Description\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b709f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_cal_stations = ridership.merge(cal, on=['year','month','day']) \\\n",
    "\t\t\t\t\t\t\t.merge(stations, on='station_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5c18fb",
   "metadata": {},
   "source": [
    "#### iii. One to many merges with multiple tables - Using suffixes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e34566e",
   "metadata": {},
   "source": [
    "the suffixes parameter is very useful when you’re merging multiple DataFrames that might have columns with the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5df64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = land_use.merge(census, on = \"ward\").merge(licenses, on = \"ward\", suffixes = [\"_cen\", \"_lic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b55fea",
   "metadata": {},
   "source": [
    "#### iv. Left Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2770d3",
   "metadata": {},
   "source": [
    "Everything is the same as shown in inner join except ```how=\"left\"``` is defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5901b0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "toystory_tag = toy_story.merge(taglines, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e897eb14",
   "metadata": {},
   "source": [
    "v. Outer Join \n",
    "\n",
    " - Everything is the same as shown in inner join except ```how=\"right\"``` is defined\n",
    " - it returns all rows from both merged tables and null where they do not match, you can use it to find rows that do not have a match in the other table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73175ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_scifi = action_movies.merge(scifi_movies, on = \"movie_id\", how = \"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7af686",
   "metadata": {},
   "source": [
    "#### vi. Merging table to itself\n",
    "\n",
    " - Use the same dataframe with suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc17ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "crews_self_merged = crews.merge(crews, on = \"id\", suffixes = [\"_dir\",\"_crew\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8499fc78",
   "metadata": {},
   "source": [
    "### c. Advanced merging and concatenation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68e2d5f",
   "metadata": {},
   "source": [
    "#### i. Performing an Anti Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0905abae",
   "metadata": {},
   "source": [
    "When you set ```indicator=True```, pandas will add a special column named \"_merge\" to the result of your merge.\n",
    "This column tells you where each row came from:\n",
    "\n",
    " - ```\"left_only\"``` → row appears only in the left DataFrame (employees here).\n",
    "\n",
    " - ```\"right_only\"``` → row appears only in the right DataFrame (top_cust).\n",
    "\n",
    " - ```\"both\"``` → row had a match in both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ebd651",
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_cust = employees.merge(top_cust, on='srid', \n",
    "                                 how='left', indicator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df50b82",
   "metadata": {},
   "source": [
    "#### ii. Concatenating the data vertically -> ```pd.concat```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56548533",
   "metadata": {},
   "source": [
    "What ```sort=True``` Means\n",
    "\n",
    "When the DataFrames don’t all have the same columns, pandas needs to reconcile column order.\n",
    "\n",
    "\"If there are mismatched columns across the DataFrames, sort the column names alphabetically in the result.\"\n",
    "\n",
    "✅ It does not sort the rows by any column.\n",
    "✅ It only affects the column labels order in the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c99947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the tracks\n",
    "tracks_from_albums = pd.concat([tracks_master,tracks_ride,tracks_st],\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2502eb71",
   "metadata": {},
   "source": [
    "Show data that are in all the tables ```join=\"inner\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5af352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the tracks, show only columns names that are in all tables\n",
    "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st],\n",
    "                               join=\"inner\",\n",
    "                               sort=True)\n",
    "print(tracks_from_albums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f98cb0",
   "metadata": {},
   "source": [
    "#### iii. Concatenating with ```Keys```\n",
    "\n",
    " - It would create a new index column to help tag rows to understand which data frame the same has arrived from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_jul_thr_sep = pd.concat([inv_jul, inv_aug,inv_sep], \n",
    "                            keys=['7Jul', '8Aug', '9Sep'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe44f912",
   "metadata": {},
   "source": [
    "Also has another parameter to help ignore index ```ignore_index=True```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012ba0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "422e755d",
   "metadata": {},
   "source": [
    "### d. Merging Ordered and time-series data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a873d207",
   "metadata": {},
   "source": [
    "#### i. merge_ordered()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899f4db",
   "metadata": {},
   "source": [
    "```.merge()``` vs ```merge_ordered()```\n",
    "\n",
    "\n",
    "<img src=\"/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Important_Scripts-Practice/1. DataCamp - Practice/Images/merge vs merge_order.png\" width=\"500\" height=\"300\" alt=\"Description\">\n",
    "\n",
    "\n",
    "<img src=\"/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Important_Scripts-Practice/1. DataCamp - Practice/Images/Forward Fill.png\" width=\"500\" height=\"300\" alt=\"Description\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dbdfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_sp500 = pd.merge_ordered(gdp, sp500, left_on='year', right_on='date', how=\"left\",fill_method='ffill')\n",
    "\n",
    "# Merge gdp and pop on date and country with fill and notice rows 2 and 3\n",
    "ctry_date = pd.merge_ordered(gdp, pop, on=[\"date\", \"country\"],\n",
    "                             fill_method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8976ebbc",
   "metadata": {},
   "source": [
    "#### ii. merge_asof() -> \n",
    "\n",
    " - similar merge_ordered() left join and has similar features of merge_ordered()\n",
    "  - What ever column it is merged on should be sorted, i.e ```on``` parameter column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cad630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use merge_asof() to merge jpm and wells\n",
    "jpm_wells = pd.merge_asof(jpm, wells, on = \"date_time\", suffixes = (\"\",\"_wells\"), direction='nearest')\n",
    "\n",
    "\n",
    "# Use merge_asof() to merge jpm_wells and bac\n",
    "jpm_wells_bac = pd.merge_asof(jpm_wells, bac, on = \"date_time\", suffixes = ('_jpm', '_bac'), direction='nearest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1333a9e",
   "metadata": {},
   "source": [
    "#### iii. ```.query()``` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cdbb72",
   "metadata": {},
   "source": [
    "#### iv. ```.melt()``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed95c4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d1894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2980c99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f11494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d0e79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_GlobalEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
